version: '3.8'

services:


  postgres:
    container_name: PostgreSQL-Madesa
    image: bitnami/postgresql:latest
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres

      - APP_DB_USER=postgres
      - APP_DB_PASS=postgres
#      - APP_DB_NAME=madesa-database
      - APP_DB_NAME=postgres
    healthcheck:
      test: [ "CMD", "pg_isready", "-q", "-d", "postgres", "-U", "root" ]
      timeout: 45s
      interval: 10s
      retries: 10
    restart: always

    volumes:
#      - ./db:/docker-entrypoint-initdb.d/
      - postgres_data:/var/lib/postgresql/data/

    ports:
      - 5432:5432

    networks:
      - frontend
      - backend


  pgadmin:
    container_name: PGAdmin-Madesa
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: getter@getter.com.br
      PGADMIN_DEFAULT_PASSWORD: getter@2022
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    volumes:
      - pgadmin:/var/lib/pgadmin
    ports:
      - "${PGADMIN_PORT:-5050}:80"


    networks:
      - frontend
      - backend


    depends_on:
      - postgres
    restart: unless-stopped


  #  nginx:
  #    container_name: NGINX-Madesa
  #    build: ./nginx
  #    volumes:
  #      - static_volume:/home/app/web/staticfiles
  #      - media_volume:/home/app/web/media
  #    ports:
  #      - 1337:80
  #
  #    networks:
  #      - frontend
  #      - backend
  #
  #    depends_on:
  #      - web

  reverse-proxy:
    # The official v2 Traefik docker image
    image: traefik:v2.2
    # Enables the web UI and tells Traefik to listen to docker
    container_name: Traefik-Madesa
    ports:
      # The HTTP port
      - 80:80
      - 443:443
      - 8008:80
      - 8081:8080
    volumes:
      # So that Traefik can listen to the Docker events
      - /var/run/docker.sock:/var/run/docker.sock
      - ./.docker/traefik/traefik.toml:/traefik.toml

    networks:
      - frontend
      - backend

  web:
    container_name: Backend-Madesa
    environment:
      - SECRET_KEY=t6g8a4oga114*9-v1p7y!cac)(j3mby(v@a63h=py_^u+wf9yb
      - DATABASE_URL=postgres://postgres:postgres@postgres:5432/postgres
      - ALLOWED_HOSTS=*
      - DEBUG=False
    build:
      context: .
      dockerfile: Dockerfile

    command: sh -c "python manage.py makemigrations && python manage.py migrate &&  gunicorn --worker-class=gevent --workers=3 --worker-connections=1000 config.wsgi:application --bind=0.0.0.0:8000 --log-level=DEBUG"

    labels:
      - "traefik.enable=true"


    ports:
      - 8000:8000

    networks:
      - frontend
      - backend



    volumes:
      - static_volume:/home/app/web/staticfiles
      - media_volume:/home/app/web/mediafiles
    depends_on:
      - postgres


  #  grafana:
  #    build: .docker/grafana
  #    container_name: Dashboard
  #    links:
  #      - postgres
  #    expose:
  #      - 3000
  #    ports:
  #      - 3000:3000
  #    environment:
  #      GF_USERS_DEFAULT_THEME: "dark"
  #
  #    networks:
  #      - frontend
  #      - backend



  apm-server:
    container_name: apm-server-container
    image: store/elastic/apm-server:7.2.1
    user: apm-server
    ports:
      - "7200:7200"
    depends_on: [ "elasticsearch", "kibana" ]
    volumes:
      - ./.docker/apm-conf/apm-server.yml:/usr/share/apm-server/apm-server.yml
    command: /usr/share/apm-server/apm-server -e -c /usr/share/apm-server/apm-server.yml -E apm-server.host=apm-server:7200 --strict.perms=false
    networks:
      - frontend
      - backend
    healthcheck:
      test: [ "CMD", "curl", "-s", "-f", "http://localhost:7200/polls" ]
      retries: 6

  heartbeat:
    container_name: heartbeat-container
    image: store/elastic/heartbeat:7.2.1
    user: heartbeat
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:

      - ./.docker/heartbeat/heartbeat.yml:/usr/share/heartbeat/heartbeat.yml
      - ./.docker/heartbeat/monitors.d:/usr/share/heartbeat/monitors.d
    command: /usr/share/heartbeat/heartbeat setup -E setup.kibana.host=kibana:5601 /usr/share/heartbeat/heartbeat -e -c /usr/share/heartbeat/heartbeat.yml --strict.perms=false
    networks:
      - frontend
      - backend
  elasticsearch:
    container_name: elasticsearch-container
    image: docker.io/elasticsearch:7.2.1
    environment:
      discovery.type: single-node
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    healthcheck:
      test: [ "CMD", "curl","-s" ,"-f", "http://localhost:9200/_cat/health" ]
    networks:
      - frontend
      - backend

  kibana:
    container_name: kibana-container
    hostname: kibana
    image: docker.io/kibana:7.2.1
    #volumes:
    #  - ./kibana.yml:/usr/share/kibana/kibana.yml
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports: [ '5601:5601' ]
    # depends_on: ["elasticsearch"]
    restart: on-failure
    healthcheck:
      test: [ "CMD", "curl", "-s", "-f", "http://localhost:5601/" ]
      retries: 6
    networks:
      - frontend
      - backend

  grafana:
    container_name: grafana-container
    hostname: grafana
    #image: grafana/grafana:6.4.3
    image: grafana/grafana:6.5.2
    user: root
    #volumes:
    #  - grafanadata:/var/lib/grafana
    environment:
      GF_SERVER_ROOT_URL: http://grafana:3000
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: secret

    ports: [ '3000:3000' ]
    depends_on: [ "elasticsearch" ]
    restart: on-failure
    healthcheck:
      test: [ "CMD", "curl", "-s", "-f", "http://localhost:3000/" ]
      retries: 6
    networks:
      - frontend
      - backend


networks:
  backend:
    driver: bridge
    name: madesa-oee-network
    external: false
    ipam:
      config:
        - subnet: 192.168.0.0/28
          gateway: 192.168.0.1

  frontend:
    driver: bridge
    name: proxy
    external: true

volumes:
  postgres_data:
    driver: local
  static_volume:
    driver: local
  media_volume:
    driver: local
  pgadmin:
  esdata:
    driver: local
  grafanadata:
    driver: local

